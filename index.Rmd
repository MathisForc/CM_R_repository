---
title: "Analyzing Sub-genres in Electronic Music"
author: "Matthijs Vork"
date: "2024-02-23"
output: 
  flexdashboard::flex_dashboard:
---

```{r setup, include=FALSE}
remotes::install_github('jaburgoyne/compmus')
library(spotifyr)
library(plotly)
library(tidyverse)
library(tidymodels)
library(usethis)
library(ggplot2)
library(flexdashboard)
library(dplyr)
library(dtw)
library(compmus)
library(ggdendro)
library(heatmaply)
library(cluster)
library(protoclust)

knitr::opts_chunk$set(echo = TRUE)
bass_house <- get_playlist_audio_features("", "2QhCZhrEXekqb13nGvLpHr")
tech_house <- get_playlist_audio_features("", "1XdDSaC9cfzSnPtZpesFsZ")
microhouse <- get_playlist_audio_features("", "71VZsDzDNSNpJluKcZ6x5Q")

get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
} 

```

<style>

.chordogram {
  text-align: center;
}

.figures {
  display: flex;
  flex-wrap: wrap;
  justify-content: space-around;
  margin-top: 20px;
}

.figure {
  margin: 0 10px;
  width: 30%;
  height: 100%;
}

.figure img {
  max-width: 100%;
  height: auto;
}

.headr{
  padding: 2% 2% 0% 5%;
  font-size: 4vmax;
}

.text {
  padding: 2% 5% 2% 5%;
  font-size: 1.3vmax;
}

.week12_header{
  padding: 2% 2% 0% 5%;
  font-size: 4vmax;
}

.week12_text{
  padding: 2% 5% 2% 5%;
  font-size: 1.3vmax;
}

.week12_figure{
  display: block;
  margin-left: auto;
  margin-right: auto;
  width: 50%;
}


</style>

Week 12
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Novelty Functions
<div class="week12_wrapper">

<div class="week12_header">
Novelty Functions
</div>

<div class="week12_text">
Another interesting approach to explore potential differences among the three sub-genres is by assessing whether a model can successfully differentiate between them. If the model shows the ability to distinguish between the sub-genres, it provides further significance to the research question. The model to be utilized is a classifier known as k-nearest neighbors (KNN). This algorithm operates as a supervised learning classifier, predicting the classification of individual data points. To adapt KNN for investigating potential differences among the sub-genres, the tracks within the corpora are represented as data points, with the three sub-genres representing distinct groupings. To train the KNN, the data points are divided into two groups: training data and test data. Since the classifier is trained on the labeled training data, which already defines the grouping of each data point, KNN operates as a supervised algorithm. After training the model, the model will make its predictions on the test data. Based on these predictions, several key metrics are established to evaluate the model's performance. True Positive (TP) indicates the correct classification of positive instances, False Positive (FP) indicates the incorrect classification of negative instances, True Negative (TN) indicates the correct classification of negative instances, and False Negative (FN) indicates the incorrect of positive instances. These metrics serve as vital tools in assessing the accuracy and effectiveness of KNN classification, offering insights into where the model may flucuate in its predictions. After training the KNN classifier on the corpora, the following predictions are made. When looking at the diagonal line in the figure there can be seen that model is able to make correct predictions. A clearer distinction between Bass House and Tech House can be seen compared to Microhouse. Microhouse has 14 True positives whereas Bass House and Tech House have 16 and 17 tracks, respectively. For Bass House the precision and recall scores are 0.86 and 0.90 (respectively), for Microhouse the precision and recall scores are 0.83 and 0.75 (respectively), and for Tech House the precision and recall scores are 0.81 and 0.85 (respectively).
</div>

<div class="week12_figure">
```{r, echo=FALSE}
indie <-
  bind_rows(
    bass_house |> mutate(playlist = "Bass House") |> slice_head(n = 20),
    tech_house |> mutate(playlist = "Tech House") |> slice_head(n = 20),
    microhouse |> mutate(playlist = "Microhouse") |> slice_head(n = 20)
  ) |> 
  add_audio_analysis()

indie_features <-
  indie |>  # For your portfolio, change this to the name of your corpus.
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

indie_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration,
    data = indie_features           # Use the same name as the previous block.
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].

indie_cv <- indie_features |> vfold_cv(5)

knn_model <-
  nearest_neighbor(neighbors = 1) |>
  set_mode("classification") |> 
  set_engine("kknn")
indie_knn <- 
  workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(knn_model) |> 
  fit_resamples(indie_cv, control = control_resamples(save_pred = TRUE))

# indie_knn |> get_conf_mat()

indie_knn |> get_conf_mat() |> autoplot(type = "heatmap")
```
</div>

<div class="week12_text">
To train the classifier, 10 features from the corpera are utilized. Optimizing the classifier may involve reducing the number of features to enhance training efficiency. By employing a random forest model, the features that exert the greatest influence on the grouping of data points can be identified. Upon applying random forest to the corpera, the following order of features are observed, indicating their influence on data point groupings. Notably, track duration and tempo exhibit the highest influence, while acousticness, instrumentalness, and liveness demonstrate minimal impact on the groupings.
</div>

<div class="week12_figure">
```{r, echo=FALSE}
forest_model <-
  rand_forest() |>
  set_mode("classification") |> 
  set_engine("ranger", importance = "impurity")
indie_forest <- 
  workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(forest_model) |> 
  fit_resamples(
    indie_cv, 
    control = control_resamples(save_pred = TRUE)
  )

# indie_forest |> get_pr()

workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(forest_model) |> 
  fit(indie_features) |> 
  pluck("fit", "fit", "fit") |>
  ranger::importance() |> 
  enframe() |> 
  mutate(name = fct_reorder(name, value)) |> 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")
```
</div>

<div class="week12_text">
If the classifier is trained again on the corpara but instead only with the 'tempo' and 'duration' features, the following figure is obtained. What is interesting to notice here is that Microhouse now has a higer rate of True positives compared to Bass House and Tech House. For Bass House the precision and recall scores are now 0.77 and 0.85 (respectively), for Microhouse the precision and recall scores are 0.85 and 0.85 (respectively), and for Tech House the precision and recall scores are 0.83 and 0.75 (respectively).
</div>

<div class="week12_figure">
```{r, echo=FALSE}
indie <-
  bind_rows(
    bass_house |> mutate(playlist = "Bass House") |> slice_head(n = 20),
    tech_house |> mutate(playlist = "Tech House") |> slice_head(n = 20),
    microhouse |> mutate(playlist = "Microhouse") |> slice_head(n = 20)
  ) |> 
  add_audio_analysis()

indie_features <-
  indie |>  # For your portfolio, change this to the name of your corpus.
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) |>
  mutate(pitches = map(pitches, compmus_normalise, "clr")) |>
  mutate_at(vars(pitches, timbre), map, bind_rows) |>
  unnest(cols = c(pitches, timbre))

indie_recipe <-
  recipe(
    playlist ~
      tempo +
      duration,
    data = indie_features           # Use the same name as the previous block.
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].

indie_cv <- indie_features |> vfold_cv(5)

knn_model <-
  nearest_neighbor(neighbors = 1) |>
  set_mode("classification") |> 
  set_engine("kknn")
indie_knn <- 
  workflow() |> 
  add_recipe(indie_recipe) |> 
  add_model(knn_model) |> 
  fit_resamples(indie_cv, control = control_resamples(save_pred = TRUE))

# indie_knn |> get_conf_mat()

indie_knn |> get_conf_mat() |> autoplot(type = "heatmap")
```
</div>


</div>

Introduction {.intro-text}
=====================================
<div class="wrapper">
<div class="headr">
Introduction
</div>
<div class="text">
The selected corpus encompasses three sub-genres: Bass House, Microhouse, and Tech House. Currently, it comprises 1127 tracks, with 153 tracks categorized as Bass House, 503 as Microhouse, and 441 as Electro House. These genres were chosen due to their ability to span a broad yet distinguishable range within the house music spectrum. The Bass House tracks are derived from compositions by Samuel Deep, Brawther, and Anil Aras, as well as from the Slapfunk label. This sub-genre emphasizes the lower spectrum of house music, characterized by powerful kicks, deep basslines, and rhythmic drums conducive to dancing. Microhouse, a sub-genre blending elements of techno with a slower tempo, features soft, cushiony kick-drums and a dreamy ambiance. The Microhouse tracks included in the corpus draw inspiration from compositions by Zip and Ricardo Villalobos, as well as releases from the Perlon label. The Tech House tracks included in the corpus are sourced from compositions by Mr C, Nathan Coles, and Buschwacka!, as well as releases from the Snatch Records label. Tech House is characterized as a fusion genre merging techno and house elements, featuring groove-driven beats, a minimalist approach, and the integration of technological sounds.

The selected corpus closely aligns with my musical interests and expertise, although there are areas where uncertainties persist. As a passionate DJ and music producer with releases on Spotify (for those interested, my profile can be found at: https://open.spotify.com/artist/1ux6lrKnUuH8POcbD6TzpF?si=Uq9N_4n_QAGJC7MmYbxiMw), my focus lies predominantly within the realm of house music. House music, characterized by a diverse spectrum of genres akin to other musical forms, encompasses a multitude of intriguing niches, with distinctions evident across various elements such as arrangement, drum patterns, sampling techniques, and tempo. Particularly within underground house music, which diverges from mainstream popular culture to cater to devoted enthusiasts, the differentiation among these niches is pronounced. Originating in Chicago's underground club scene in the 1980s, underground house music swiftly gained traction in Europe, with the UK actively participating in its evolution. During those years, thousands of vinyl records were pressed, each release typically limited to a small number of copies owing to the niche nature of the genre. Countries such as Germany, Italy, The Netherlands, and Sweden swiftly embraced and enriched the underground house music scene. Even today, at parties and festivals, these vintage records seamlessly intertwine with contemporary releases, showcasing the timeless qualities of certain productions from earlier years. While the visible complexity within these niches is undeniable, discussions with fellow composers often center around the perceived simplicity of house music. The question arises: "Isn't house music merely a repetitive 4/4 drum beat coupled with a basic arrangement template (intro, buildup, outro)?" In my perspective, the answer lies in both affirmation and negation. While many tracks categorized as house music exhibit repetitiveness and adhere to a basic arrangement template, the vast distinctions across various musical elements within the niches of underground house music underscore the complexity inherent in the genre. In this research, I aim to utilize the Spotify API as a third party in this discourse, shedding new light on the discussion by providing insights into the intricacies of house music.


The research examines the following main research question: 'How do the features extracted from the Spotify API contribute to understanding the extent of repetitiveness, complexity, and creative variation within House music as a genre?'. To address this question, the research is divided into several parts, each examining different aspects of music using the features provided by the Spotify API.
</div>
</div>

Week 11
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Novelty Functions
<div class="wrapper">

<div class="headr">
Novelty Functions
</div>
<div class="text">
These figures depict the Novelty Functions of three tracks within the corpus. I still can't really tell what Novelty Functions depict. If someone can help me on this it would be greatly appreciated.
</div>

<div class="figures">
<div class="figure">

```{r, echo=FALSE}
pata_pata <-
  get_tidy_audio_analysis("4uAxqp5rBBvm6eKXuAavIZ") |>
  select(segments) |>
  unnest(segments)

pata_pata |>
  mutate(loudness_max_time = start + loudness_max_time) |>
  arrange(loudness_max_time) |>
  mutate(delta_loudness = loudness_max - lag(loudness_max)) |>
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  ggtitle("Bass House: 'Larry de Kat - Def Joint'") +
  geom_line() +
  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")
```
</div>

<div class="figure">

```{r, echo=FALSE}
pata_pata <-
  get_tidy_audio_analysis("470lb3XFRIOFT7pb19fKni") |>
  select(segments) |>
  unnest(segments)

pata_pata |>
  mutate(loudness_max_time = start + loudness_max_time) |>
  arrange(loudness_max_time) |>
  mutate(delta_loudness = loudness_max - lag(loudness_max)) |>
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  ggtitle("Microhouse: 'Tom Ellis - Yah Yah'") +
  geom_line() +
  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")
```
</div>

<div class="figure">

```{r, echo=FALSE}
pata_pata <-
  get_tidy_audio_analysis("7LHbSCq1bnwfAdeAvTtHgA") |>
  select(segments) |>
  unnest(segments)

pata_pata |>
  mutate(loudness_max_time = start + loudness_max_time) |>
  arrange(loudness_max_time) |>
  mutate(delta_loudness = loudness_max - lag(loudness_max)) |>
  ggplot(aes(x = loudness_max_time, y = pmax(0, delta_loudness))) +
  ggtitle("Tech House: 'Nathan Coles - Hide & Seek'") +
  geom_line() +
  xlim(0, 30) +
  theme_minimal() +
  labs(x = "Time (s)", y = "Novelty")
```
</div>
</div>
</div>

### Tempograms
<div class="wrapper">

<div class="headr">
Tempograms
</div>
<div class="text">
The figures presented depict the Tempograms of three tracks from the corpus, each demonstrating minimal variation in tempo. However, in the Bass House track, the Spotify API identifies a noticeable shift in tempo, though it inaccurately interprets this as a significant change when it is merely a slight buildup within the track. The Microhouse track exhibits a consistent tempo with some background noise evident. Additionally, the track incorporates sound effects of people talking and ambient noise from a restaurant kitchen, which likely interferes with the accuracy of the tempo detected by the Spotify API, resulting in a less distinct tempo line. The Tech House track maintains a constant tempo throughout its duration. Notably, the bass drum remains consistently prominent throughout the track, contrasting with the Bass House track. This characteristic may contribute to the Spotify API's ability to make a strong assumption about the tempo of the Tech House track. All three tracks closely hover around 126 BPM. These figures demonstrate that the Spotify API perceives House music as a genre characterized by tracks with a consistently stable tempo, all hovering around the same BPM.
</div>

<div class="figures">
<div class="figure">

```{r, echo=FALSE}
graveola <- get_tidy_audio_analysis("7eiYOdSebHEUU4sQfaifLS")

graveola |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  ggtitle("Bass House: 'Julien Fuentes, Borren - Seabert'") +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

</div>

<div class="figure">

```{r, echo=FALSE}
graveola <- get_tidy_audio_analysis("30o5OLtfYd1MBLoGC85N6A")

graveola |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  ggtitle("Microhouse: 'Plusculaar - Rhadoo Le (Original Mix)'") +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

</div>

<div class="figure">

```{r, echo=FALSE}
graveola <- get_tidy_audio_analysis("15NAPmf13bSFdH3psDdxTU")

graveola |>
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  ggtitle("Tech House: 'Terry Francis - Hannah's Dub'") +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

</div>
</div>
</div>

Week 10
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Chordograms
<div class="wrapper">
<div class="headr">
Chordograms
</div>
<div class="text">
These figures depict the chord progressions from three tracks within the corpus. All three tracks exhibit minimal variation in chord structure throughout. In the electro track, no singular chord prominently stands out in contrast to other genres. However, in the house track, it is evident which chords are emphasized. When listening to the track, the distinct chords are clearly audible. These findings reinforce the notion that the electronic music genre tends to feature simpler chord progressions. In my opinion, this figure isn't particularly suitable for electronic music, as tracks within this genre often remain within a single chord region and prioritize percussion and repetitive basslines.
</div>

<div class="figures">
<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("4H2qrfuQQdSTPL7c0QV7mD") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("House: 'De Projekt - Catch De Play'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>

<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("7iGycpZv7eek2mf9X8oyDx") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("'Minimal: Junes - Cafe Nostalgia'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>

<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("1s84YaJC06MjSCXoOnCwAj") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("Electro: 'Breaka - Liquid Gold'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>
</div>
</div>

### Keygrams
<div class="wrapper">

<div class="headr">
Keygrams
</div>
<div class="text">
These figures illustrate the key progressions of three tracks within the corpus. Each track displays minimal variation in chord structure, with the minimal track exhibiting slightly more variation compared to the others, yet still maintaining stability. This further emphasizes the tendency of electronic music to feature simpler key progressions. In my view, this figure may not be well-suited for electronic music analysis, given that tracks in this genre often remain within a single chord region and emphasize percussion and repetitive basslines.
</div>

<div class="figures">
<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("4H2qrfuQQdSTPL7c0QV7mD") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("House: 'De Projekt - Catch De Play'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>

<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("7iGycpZv7eek2mf9X8oyDx") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("'Minimal: Junes - Cafe Nostalgia'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>

<div class="figure">

```{r, echo=FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )

twenty_five <-
  get_tidy_audio_analysis("1s84YaJC06MjSCXoOnCwAj") |>
  compmus_align(sections, segments) |>
  select(sections) |>
  unnest(sections) |>
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

twenty_five |>
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "euclidean",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) |>
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  ggtitle("Electro: 'Breaka - Liquid Gold'") +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")
```
</div>
</div>
</div>

Week 9
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Cepstrograms
<div class="wrapper">
<div class="headr">
Cepstrograms
</div>
<div class="text">
These figures depict the cepstrograms of three tracks within the corpus. In the house track, a stable pattern is evident, with a noticeable build-up around 165 seconds. Towards the outro, there's a shift towards more percussion and less harmony. The minimal track exhibits constant fluctuations, attributed to its repetitive melody. Around 210 seconds, there's a discernible build-up primarily driven by percussion. In the electro track, clear repetitions are noticable, with the beginning of the track almost duplicated after 120 seconds, a common characteristic in electronic music.
</div>
<div class="figures">
<div class="figure">
```{r, echo=FALSE}
bzt_house <-
  get_tidy_audio_analysis("7HGVGFxjlifmvUpo4owTcL") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bzt_house |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("House: 'JANC1 - Julian Alexander'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +
  theme_classic()
```
</div>
<div class="figure">
```{r, echo=FALSE}
bzt_minimal <-
  get_tidy_audio_analysis("0UBLJwRvgy8Jhyo6jTXYZR") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bzt_minimal |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Minimal: 'Tuesdays - Buschwacka!'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +
  theme_classic()
```
</div>
<div class="figure">
```{r, echo=FALSE}
bzt_electro <-
  get_tidy_audio_analysis("3gAVzxCCo8zNlZDYsseJq7") |> # Change URI.
  compmus_align(bars, segments) |>                     # Change `bars`
  select(bars) |>                                      #   in all three
  unnest(bars) |>                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) |>
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

bzt_electro |>
  compmus_gather_timbre() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Electro: 'Disaffected - OS 11'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  scale_fill_viridis_c() +
  theme_classic()
```
</div>
</div>
</div>

### Self-Similarity Matrices
<div class="wrapper">
<div class="headr">
Self-Similarity Matrices
</div>
<div class="text">
These figures display the Self-Similarity Matrices of three tracks within the corpus. In the house track, the build-up around 165 seconds is clearly visible. Additionally, numerous subtle changes are apparent, possibly indicating shifts in percussion, a characteristic of Julien Alexander's production style. In the minimal track, constant fluctuations are observed, stemming from its repetitive melody. The previously noted build-up around 210 seconds is less pronounced, but both the intro and outro are clearly depicted in this figure. In the electro track, the repetition in organization is evident.
</div>
<div class="figures">
<div class="figure">
```{r, echo=FALSE}
bzt_house |>
  compmus_self_similarity(timbre, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  ggtitle("House: 'JANC1 - Julian Alexander'") +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```
</div>
<div class="figure">
```{r, echo=FALSE}
bzt_minimal |>
  compmus_self_similarity(timbre, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  ggtitle("Minimal: 'Tuesdays - Buschwacka!'") +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```
</div>
<div class="figure">
```{r, echo=FALSE}
bzt_electro |>
  compmus_self_similarity(timbre, "cosine") |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  ggtitle("Electro: 'Disaffected - OS 11'") +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "")
```
</div>
</div>
</div>

Week 8
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Chromagrams
<div class="wrapper">
<div class="headr">
Chromagrams
</div>
<div class="text">
These figures present the chromagrams of three tracks from the corpus. In the house track, a less consistent pattern is noticeable, with clear changes in structure throughout the track. Two bridges and build-ups are evident, along with a longer outro compared to the intro. In the minimal track, a distinct static repetitive structure is visible, reaffirming the characteristic of minimal house music. Similarly, in the electro track, repetition is evident, with two bridges around 40 and 140 seconds, and an outro around 215 seconds that alters the energy of the track.
</div>
<div class="figures">
<div class="figure">
```{r, echo=FALSE}
wood <-
  get_tidy_audio_analysis("4R0lg0dcpePAao09jJFy0R") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)


wood |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("House: 'Soul Mass Transit System - Wine'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
</div>
<div class="figure">
```{r, echo=FALSE}
wood <-
  get_tidy_audio_analysis("49G8l1W2DTS6WyT6RBWKIO") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)


wood |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Minimal: 'Losoul - Below The Clouds (Original Mix)'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
</div>
<div class="figure">
```{r, echo=FALSE}
wood <-
  get_tidy_audio_analysis("3wnf2NB94kYM9mYYekeqrY") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)


wood |>
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) |>
  compmus_gather_chroma() |>
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Electro: 'DJ MELL G - Juicy Gang'") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```
</div>
</div>
</div>

### Dynamic Time Warping
<div class="wrapper">
<div class="headr">
Dynamic Time Warping
</div>
<div class="text">
These visuals exhibit the dynamic time warping of three tracks from the corpus.
</div>
<div class="figures">
<div class="figure">
```{r, echo=FALSE}
## Electro: Setaoc Mass - Disrepair
setaoc <-
  get_tidy_audio_analysis("5GQaG7S1blUhspT0Dzhngg") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
## Minimal: Petre Inspirescu - Sakadat
sakadat <-
  get_tidy_audio_analysis("1rnTSEBS2oVLlRBLOQiomo") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

compmus_long_distance(
  setaoc |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  sakadat |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  ggtitle("House") +
  coord_equal() +
  labs(x = "Brawther - Basix (Deep Mix)", y = "William Caycedo - Roasted (Original Mix)") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)
```
</div>
<div class="figure">
```{r, echo=FALSE}
## Electro: Setaoc Mass - Disrepair
setaoc <-
  get_tidy_audio_analysis("5JcTPYvJmKbgQa9tffD3fg") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
## Minimal: Petre Inspirescu - Sakadat
sakadat <-
  get_tidy_audio_analysis("5GDnFk9M3qPlTKY4XIgYdl") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

compmus_long_distance(
  setaoc |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  sakadat |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  ggtitle("Minimal") +
  coord_equal() +
  labs(x = "iO (Mulen) - Stick Out", y = "Ricardo Villalobos - Logohitz") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)
```
</div>
<div class="figure">
```{r, echo=FALSE}
## Electro: Setaoc Mass - Disrepair
setaoc <-
  get_tidy_audio_analysis("4Co3Fmz3EpfiQE3U5HfoMY") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)
## Minimal: Petre Inspirescu - Sakadat
sakadat <-
  get_tidy_audio_analysis("5oisJqdx3cXLCd9H5Xdvzc") |>
  select(segments) |>
  unnest(segments) |>
  select(start, duration, pitches)

compmus_long_distance(
  setaoc |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  sakadat |> mutate(pitches = map(pitches, compmus_normalise, "chebyshev")),
  feature = pitches,
  method = "euclidean"
) |>
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  ggtitle("Electro") +
  coord_equal() +
  labs(x = "Ludwig A.F. - First Flight", y = "D.I.E. - Programming") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)
```
</div>
</div>
</div>


Week 7
=====================================

Row {.tabset .tabset-fade}
-------------------------------------

### Tempo analysis
<div class="week12_wrapper">

<div class="week12_header">
Tempo analysis
</div>

<div class="week12_text">
This figure depicts a boxplot with the x-axis representing the categories of the Corpus and the y-axis representing the tempo of the tracks in beats per minute (BPM). Notably, the tempo for the electro category surpasses that of the remaining categories. The mean tempo for electro is around 135 BPM, whereas for the other categories, it remains close to 125 BPM. Both categories exhibit tight clustering around their respective means. Additionally, the plots reveal the presence of outliers, underscoring the distinct stylistic attributes inherent to each genre. This observation representing to the unique characteristics defining the genres, offering valuable insights into their individual musical styles.
</div>

<div class="week12_figure">
```{r, echo=FALSE}
categories <-
  bind_rows(
    bass_house |> mutate(category = "Bass House"),
    microhouse |> mutate(category = "Microhouse"),
    tech_house |> mutate(category = "Tech House")
  )

categories |>
  ggplot(aes(x = category, y = tempo)) +
  geom_violin()
```
</div>
</div>

### Duration analysis
<div class="week12_wrapper">

<div class="week12_header">
Duration analysis
</div>

<div class="week12_text">
This figure presents a boxplot, with the x-axis representing the categories of the Corpus and the y-axis representing the duration of the tracks. Notably, the electro category exhibits shorter durations compared to the other categories. Conversely, the minimal category displays less condensation than the others, demonstrating a higher variance and containing numerous outliers. This divergence underscores the distinct stylistic attributes inherent to each genre, offering intersting insights into their respective characteristics.
</div>

<div class="week12_figure">
```{r, echo=FALSE}
categories <-
  bind_rows(
    bass_house |> mutate(category = "Bass House"),
    microhouse |> mutate(category = "Microhouse"),
    tech_house |> mutate(category = "Tech House")
  )

categories |>
  ggplot(aes(x = category, y = track.duration_ms)) +
  geom_violin()
```
</div>
</div>